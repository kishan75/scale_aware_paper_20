{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Local feature extractor (LFE)","metadata":{}},{"cell_type":"code","source":"import sys\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nlearning_rate = 0.00001\nbatch_size = 8\nnum_epoch = 1\n\nclass LFE(nn.Module):\n    def __init__(self):\n        super(LFE, self).__init__()\n        self.conv_1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), stride=(1, 1), dilation = 1,\n                               padding='same')\n        self.pool_1 = nn.MaxPool2d(2, stride=(2))\n        self.conv_2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), stride=(1, 1), dilation = 1,\n                               padding='same')\n        self.pool_2 = nn.MaxPool2d(2, stride=(2))\n        self.conv_3 = nn.Conv2d(in_channels=32, out_channels=48, kernel_size=(3, 3), stride=(1, 1), dilation = 1,\n                               padding='same')\n        self.conv_4 = nn.Conv2d(in_channels=48, out_channels=48, kernel_size=(3, 3), stride=(1, 1), dilation = 1,\n                               padding='same')\n        self.pool_3 = nn.MaxPool2d(2, stride=(2))\n        self.conv_5 = nn.Conv2d(in_channels=48, out_channels=64, kernel_size=(3, 3), stride=(1, 1), dilation = 1,\n                               padding='same')\n        self.conv_6 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=(1, 1), dilation = 1,\n                               padding='same')\n        self.conv_7 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=(1, 1), dilation = 1,\n                               padding='same')\n    def forward(self, x):\n        x = self.conv_1(x)\n        print(\"conv_1 \",x.shape)\n        x = self.pool_1(x)\n        print(\"pool_1 \",x.shape)\n        x = self.conv_2(x)\n        print(\"conv_2 \",x.shape)\n        x = self.pool_2(x)\n        print(\"pool_2\",x.shape)\n        x = self.conv_3(x)\n        print(\"conv_3 \",x.shape)\n        x = self.conv_4(x)\n        print(\"conv_4 \",x.shape)\n        x = self.pool_3(x)\n        print(\"pool_3 \",x.shape)\n        x = self.conv_5(x)\n        print(\"conv_5\",x.shape)\n        x = self.conv_6(x)\n        print(\"conv_6\",x.shape)\n        x = self.conv_7(x)\n        print(\"conv_7\",x.shape)\n        return x\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-08T11:56:06.512254Z","iopub.execute_input":"2022-02-08T11:56:06.513045Z","iopub.status.idle":"2022-02-08T11:56:08.172003Z","shell.execute_reply.started":"2022-02-08T11:56:06.513001Z","shell.execute_reply":"2022-02-08T11:56:08.170930Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model = LFE()\nlfe_out = torch.rand(3,3,768,1024)\nlfe_out = model(lfe_out)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T11:56:10.269618Z","iopub.execute_input":"2022-02-08T11:56:10.270264Z","iopub.status.idle":"2022-02-08T11:56:11.673119Z","shell.execute_reply.started":"2022-02-08T11:56:10.270201Z","shell.execute_reply":"2022-02-08T11:56:11.672161Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"conv_1  torch.Size([3, 16, 768, 1024])\npool_1  torch.Size([3, 16, 384, 512])\nconv_2  torch.Size([3, 32, 384, 512])\npool_2 torch.Size([3, 32, 192, 256])\nconv_3  torch.Size([3, 48, 192, 256])\nconv_4  torch.Size([3, 48, 192, 256])\npool_3  torch.Size([3, 48, 96, 128])\nconv_5 torch.Size([3, 64, 96, 128])\nconv_6 torch.Size([3, 64, 96, 128])\nconv_7 torch.Size([3, 64, 96, 128])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Hybrid dilation convolution (HDC) block","metadata":{}},{"cell_type":"code","source":"class HDC(nn.Module):\n    def __init__(self):\n        super(HDC, self).__init__()\n        self.conv_1 = nn.Conv2d(in_channels=64, out_channels=16, kernel_size=(1, 1), stride=(1, 1), dilation = 1,\n                               padding='same')\n        self.conv_2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), stride=(1, 1), dilation = 1,\n                               padding='same')\n        self.conv_3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), stride=(1, 1), dilation = 2,\n                               padding='same')\n        self.conv_4 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), stride=(1, 1), dilation = 3,\n                               padding='same')\n        \n    def forward(self,i):\n        print(\"input shape i \",i.shape)\n        i_0 = self.conv_1(i)\n        print(\"conv_1 \",i_0.shape)\n        i_1 = self.conv_2(i_0)\n        print(\"conv_2 \",i_1.shape)\n        i_2 = self.conv_3(i_1)\n        print(\"conv_3 \",i_2.shape)\n        i_3 = self.conv_4(i_2)\n        print(\"conv_4 \",i_3.shape)\n        c = torch.cat((i_0,i_1,i_2,i_3),dim=1)\n        out = c+i\n        print(\"after skip connection addition\",out.shape)\n        \n        return out\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T11:56:14.426151Z","iopub.execute_input":"2022-02-08T11:56:14.426470Z","iopub.status.idle":"2022-02-08T11:56:14.438697Z","shell.execute_reply.started":"2022-02-08T11:56:14.426439Z","shell.execute_reply":"2022-02-08T11:56:14.437756Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model = HDC()\nhdc_out = model(lfe_out)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T11:56:20.216639Z","iopub.execute_input":"2022-02-08T11:56:20.216944Z","iopub.status.idle":"2022-02-08T11:56:20.264458Z","shell.execute_reply.started":"2022-02-08T11:56:20.216914Z","shell.execute_reply":"2022-02-08T11:56:20.263818Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"input shape i  torch.Size([3, 64, 96, 128])\nconv_1  torch.Size([3, 16, 96, 128])\nconv_2  torch.Size([3, 16, 96, 128])\nconv_3  torch.Size([3, 16, 96, 128])\nconv_4  torch.Size([3, 16, 96, 128])\nafter skip connection addition torch.Size([3, 64, 96, 128])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Efficient attention-based fusion (EAF) block","metadata":{}},{"cell_type":"code","source":"class EAF(nn.Module):\n    def __init__(self):\n        super(EAF, self).__init__()\n        \n        self.glb_avg_pool_w1 = nn.AvgPool2d((96,128))\n        self.glb_avg_pool_w2 = nn.AvgPool2d((96,128))\n\n        self.conv_w1 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=(9), stride=(1),\n                               padding='same')\n        self.conv_w2 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=(9), stride=(1),\n                               padding='same')\n        \n        self.norm = nn.InstanceNorm2d(64)\n        \n        self.conv_out = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(1), stride=(1, 1),\n                               padding='same')\n\n    def forward(self,x1,x2):\n        print(\"x1_shape \",x1.shape)\n        print(\"x2_shape \",x2.shape)\n\n        w1 = self.glb_avg_pool_w1(x1)\n        print(\"after global average pool w1 \",w1.shape)\n        w2 = self.glb_avg_pool_w1(x2)\n        print(\"after global average pool w1 \",w2.shape)\n        \n        w1 = torch.reshape(w1,(w1.shape[0],w1.shape[1],1))\n        print(\"reshape w1 \",w1.shape)\n        w2 = torch.reshape(w2,(w2.shape[0],w2.shape[1],1))\n        print(\"reshape w2 \",w2.shape)\n        w = torch.cat((w1,w2),dim=1)\n        print(\"concated w1 and w2 \",w.shape)\n        \n        w = w.reshape(w.shape[0],w.shape[2],w.shape[1])\n        \n        w1 = self.conv_w1(w)\n        print(\"conv_1 \",w1.shape)\n        w2 = self.conv_w2(w)\n        print(\"conv_1 \",w2.shape)\n        \n        w1 = F.softmax(torch.reshape(w1,(w1.shape[0],w1.shape[3],1,1)),dim=1) \n        print(\"conv_1 \",w1.shape)\n        w2 = F.softmax(torch.reshape(w2,(w2.shape[0],w2.shape[3],1,1)),dim=1)\n        print(\"conv_1 \",w2.shape)\n        \n        w1 = torch.mul(w1, x1)\n        print(\"conv_1 \",w1.shape)\n        w2 = torch.mul(w2, x2)\n        print(\"conv_1 \",w2.shape)\n        \n        out = torch.sum(w1, w2, x1, x2)\n        print(\"conv_1 \",i_0.shape)\n        \n        out = self.norm(out)\n        print(\"conv_1 \",i_0.shape)\n        \n        out = self.conv_out(out)\n        print(\"conv_1 \",i_0.shape)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2022-02-08T12:14:29.628292Z","iopub.execute_input":"2022-02-08T12:14:29.629215Z","iopub.status.idle":"2022-02-08T12:14:29.647322Z","shell.execute_reply.started":"2022-02-08T12:14:29.629177Z","shell.execute_reply":"2022-02-08T12:14:29.646421Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model = EAF()\nprint(model(hdc_out,lfe_out))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T12:14:31.929729Z","iopub.execute_input":"2022-02-08T12:14:31.930519Z","iopub.status.idle":"2022-02-08T12:14:32.033940Z","shell.execute_reply.started":"2022-02-08T12:14:31.930482Z","shell.execute_reply":"2022-02-08T12:14:32.033172Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"x1_shape  torch.Size([3, 64, 96, 128])\nx2_shape  torch.Size([3, 64, 96, 128])\nafter global average pool w1  torch.Size([3, 64, 1, 1])\nafter global average pool w1  torch.Size([3, 64, 1, 1])\nreshape w1  torch.Size([3, 64, 1])\nreshape w2  torch.Size([3, 64, 1])\nconcated w1 and w2  torch.Size([3, 128, 1])\nconv_1  torch.Size([3, 1, 128])\nconv_1  torch.Size([3, 1, 128])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/2664087490.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEAF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdc_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlfe_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_34/1863183905.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"conv_1 \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"conv_1 \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"],"ename":"IndexError","evalue":"tuple index out of range","output_type":"error"}]},{"cell_type":"code","source":"m = nn.InstanceNorm2d(100)\ninput = torch.randn(20, 100, 35, 45)\noutput = m(input)\nprint(output.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scale feature fusion module (SFFM)","metadata":{}},{"cell_type":"code","source":"class SFFM(nn.Module):\n    def __init__(self,lfe,hdc2,hdc4,hdc6):\n        super(SFFM, self).__init__()\n        self.lfe = lfe\n        self.hdc2 = hdc2\n        self.hdc4 = hdc4\n        self.hdc6 = hdc6\n        \n        self.eaf1 = EAF()\n        self.eaf2 = EAF()\n        self.eaf3 = EAF()\n\n\n    def forward(self):\n        lfe = self.lfe\n        print(\"lfe shape \",lfe.shape)\n        hdc2 = self.hdc2 \n        print(\"hdc2 shape \",hdc2.shape)\n        hdc4 = self.hdc4\n        print(\"hdc4 shape \",hdc4.shape)\n        hdc6 = self.hdc6  \n        print(\"hdc6 shape \",hdc6.shape)\n        \n        feature_map = self.eaf1(lfe,hdc2)\n        print(\"feature_map shape\",feature_map.shape)\n        feature_map = self.eaf2(feature_map,hdc4)\n        print(\"feature_map shape\",feature_map.shape)\n        feature_map = self.eaf3(feature_map,hdc6)\n        print(\"feature_map shape\",feature_map.shape)\n        \n        out = feature_map + lfe\n        print(\"out shape \",out.shape)\n        \n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SFFM(lfe_out,hdc_out,hdc_out,hdc_out)\nmodel = model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Density map regressor (DMR)","metadata":{}},{"cell_type":"code","source":"class DMR(nn.Module):\n    def __init__(self):\n        super(DMR, self).__init__()\n        self.conv_1 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=(3, 3), stride=(1, 1), dilation = 1,\n                               padding='same')\n        self.deconv_1 = nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=(2, 2), stride=(2,2))\n        self.conv_2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(3, 3), stride=(1, 1), dilation = 1,\n                               padding='same')\n        self.deconv_2 = nn.ConvTranspose2d(in_channels=8, out_channels=4, kernel_size=(2, 2), stride=(2,2))\n        self.conv_3 = nn.Conv2d(in_channels=4, out_channels=4, kernel_size=(3, 3), stride=(1, 1), dilation = 2,\n                               padding='same')\n        self.deconv_3 = nn.ConvTranspose2d(in_channels=4, out_channels=1, kernel_size=(2, 2), stride=(2,2))\n        \n    def forward(self,x):\n        print(\"input shape x \",x.shape)\n        x = self.conv_1(x)\n        print(\"conv_1 \",x.shape)\n        x = self.deconv_1(x)\n        print(\"deconv_1 \",x.shape)\n        x = self.conv_2(x)\n        print(\"conv_2 \",x.shape)\n        x = self.deconv_2(x)\n        print(\"deconv_2 \",x.shape)\n        x = self.conv_3(x)\n        print(\"conv_3 \",x.shape)\n        x = self.deconv_3(x)\n        print(\"deconv_3 \",x.shape)\n        \n        return x\n","metadata":{"execution":{"iopub.status.busy":"2022-02-08T12:26:06.952988Z","iopub.execute_input":"2022-02-08T12:26:06.953349Z","iopub.status.idle":"2022-02-08T12:26:06.968595Z","shell.execute_reply.started":"2022-02-08T12:26:06.953302Z","shell.execute_reply":"2022-02-08T12:26:06.967673Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model = DMR()\nlfe_out = torch.rand(3,64,96,128)\nlfe_out = model(lfe_out)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T12:26:11.393682Z","iopub.execute_input":"2022-02-08T12:26:11.394003Z","iopub.status.idle":"2022-02-08T12:26:11.604560Z","shell.execute_reply.started":"2022-02-08T12:26:11.393961Z","shell.execute_reply":"2022-02-08T12:26:11.603412Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"input shape x  torch.Size([3, 64, 96, 128])\nconv_1  torch.Size([3, 32, 96, 128])\ndeconv_1  torch.Size([3, 16, 192, 256])\nconv_2  torch.Size([3, 8, 192, 256])\ndeconv_2  torch.Size([3, 4, 384, 512])\nconv_3  torch.Size([3, 4, 384, 512])\ndeconv_3  torch.Size([3, 1, 768, 1024])\n","output_type":"stream"}]},{"cell_type":"code","source":"def isPalindrome(s):\n    return s == s[::-1]\n\ndef spiralPrint(a):\n    k = 0\n    l = 0\n    m = len(a)\n    n = len(a[0])\n    ans = []\n    st = ''\n \n    while (k < m and l < n):\n \n        for i in range(l, n):\n            st += a[k][i]\n            if len(st)>1 and isPalindrome(st):\n                ans.append(st)\n                st=''\n            \n        k += 1\n \n        for i in range(k, m):\n            st += a[i][n - 1]\n            if len(st)>1 and isPalindrome(st):\n                ans.append(st)\n                st=''\n \n        n -= 1\n \n        if (k < m):\n \n            for i in range(n - 1, (l - 1), -1):\n                st += a[m - 1][i]\n                if len(st)>1 and isPalindrome(st):\n                    ans.append(st)\n                    st=''\n \n            m -= 1\n \n        if (l < n):\n            for i in range(m - 1, k - 1, -1):\n                st += a[i][l]\n                if len(st)>1 and isPalindrome(st):\n                    ans.append(st)\n                    st=''\n \n            l += 1\n    \n    \n    ans.append(st)        \n    return ans\n\n\n\n\ninput_arr = []\nm = int(input(\"number of rows\"))\nfor i in range(m):\n    st = input(\"enter string \")\n    input_arr.append(st.split(','))\n\nprint(input_arr)\noutstr = spiralPrint(input_arr)\n\nans = outstr[0]\n\nfor i in range(len(outstr)-1):\n    ans+=','\n    ans+=outstr[i+1]\n    \nprint(ans)\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def power(x, y):\n      \n    if y == 0:\n        return 1\n    if y % 2 == 0:\n        return power(x, y // 2) * power(x, y // 2)\n          \n    return x * power(x, y // 2) * power(x, y // 2)\n  \n# Function to calculate order of the number\ndef order(x):\n  \n    # Variable to store of the number\n    n = 0\n    while (x != 0):\n        n = n + 1\n        x = x // 10\n          \n    return n\n  \n# Function to check whether the given \n# number is Armstrong number or not\ndef isArmstrong(x):\n      \n    n = order(x)\n    temp = x\n    sum1 = 0\n      \n    while (temp != 0):\n        r = temp % 10\n        sum1 = sum1 + power(r, n)\n        temp = temp // 10\n  \n    # If condition satisfies\n    return (sum1 == x)\n\ninstr = input(\"input string\")\nascii_val = [ord(ch) for ch in instr]\ntotal_sum = sum(ascii_val)\n\n\nif isArmstrong(total_sum):\n    check={}\n    outstr=''\n    for ele in ascii_val:\n        if chr(ele) in check:\n            pass\n        else:\n            outstr+=chr(ele)\n            check[chr(ele)]=1\n    print(outstr)\nelse:\n    print('-1')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}